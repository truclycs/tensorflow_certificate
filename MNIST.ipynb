{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNrwNRqfrmjcfElE8DjN3IS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0fnMDDrFbBIL"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4koIEOjMa6Ri","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609007404633,"user_tz":-420,"elapsed":3517,"user":{"displayName":"Ly Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64","userId":"01585632328413993117"}},"outputId":"c5d0d5b7-2cbd-4000-b762-5ba1671e65ac"},"source":["(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tTCRRqIeUE1T"},"source":["Hiển thị thử một mẫu và nhãn tương ứng trong tập dữ liệu MNIST"]},{"cell_type":"code","metadata":{"id":"RIn0QWBbGcnB"},"source":["print(\"Label:\", training_labels[0])\n","plt.imshow(training_images[0]);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QB3yyoXUL57"},"source":["Kích thước của tập dữ liệu là `(60000, 28, 28)` tương ứng với 60000 ảnh, mỗi ảnh có kích thước (28 x 28)"]},{"cell_type":"code","metadata":{"id":"JheKPXBHJdmP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609007404636,"user_tz":-420,"elapsed":3503,"user":{"displayName":"Ly Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64","userId":"01585632328413993117"}},"outputId":"cb185b2b-b9d3-4e54-bf58-cc2cbf5413fa"},"source":["training_images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"QiDXD9Q9UsS8"},"source":["## Chuẩn hóa dữ liệu\n","\n","Chuẩn hóa lại dữ liệu bằng cách chia các giá trị của pixel cho 255.0."]},{"cell_type":"code","metadata":{"id":"nCpRcq-kU9Il"},"source":["import numpy as np\n","normalize = lambda data_img : np.reshape(data_img / 255.0, (*data_img.shape, 1))\n","\n","training_images = normalize(training_images)\n","test_images = normalize(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"juTAcHuRDyyN"},"source":["## Kiến trúc mô hình"]},{"cell_type":"code","metadata":{"id":"Vw6mkm8LVoWW"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfNST0PMav6E","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1609007410487,"user_tz":-420,"elapsed":9339,"user":{"displayName":"Ly Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64","userId":"01585632328413993117"}},"outputId":"5402744a-d6eb-47a9-8339-b93298d61bc8"},"source":["# Khởi tạo model\n","model = Sequential()\n","\n","model.add()\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.1))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(units=128, activation=\"relu\"))\n","model.add(Dropout(0.25))\n","model.add(Dense(units=10, activation=\"softmax\"))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-8ae7c261184d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: add() missing 1 required positional argument: 'layer'"]}]},{"cell_type":"code","metadata":{"id":"dLSdfhuLaxRO"},"source":["lrs = [1e-3, 1e-4, 1e-6]\n","epochs = [20, 15, 20]\n","\n","# Tiến hành training, Sử dụng test_images, test_labels để làm tập validation\n","for lr, epoch in zip(lrs, epochs):\n","  print(\"Learning rate:\", lr)\n","  optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr, momentum=5e-3)\n","  model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=\"acc\")\n","  model.fit(x=training_images, y=training_labels, batch_size=64, epochs=epoch, validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2585,
     "status": "ok",
     "timestamp": 1609040916929,
     "user": {
      "displayName": "Ly Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64",
      "userId": "01585632328413993117"
     },
     "user_tz": -420
    },
    "id": "h8e06OZfRVtF",
    "outputId": "badf2e82-3ad8-4c4c-f9d9-17728a03b40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"article_link\": \"https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5\", \"headline\": \"former versace store clerk sues over secret 'black code' for minority shoppers\", \"is_sarcastic\": 0},\n",
      "{\"article_link\": \"https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365\", \"headline\": \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"is_sarcastic\": 0},\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Get the dataset\n",
    "srcsm_json = requests.get('https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json')\n",
    "# Inspecting the data, print 450 characters\n",
    "print(srcsm_json.text[0:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2573,
     "status": "ok",
     "timestamp": 1609040916935,
     "user": {
      "displayName": "Ly Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64",
      "userId": "01585632328413993117"
     },
     "user_tz": -420
    },
    "id": "pBDzKSIJRbwB",
    "outputId": "ba36f1f1-25fa-4ca6-f14a-1bc6146738bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  label\n",
      "0  former versace store clerk sues over secret 'b...      0\n",
      "1  the 'roseanne' revival catches up to our thorn...      0\n",
      "2  mom starting to fear son's web series closest ...      1\n",
      "3  boehner just wants wife to listen, not come up...      1\n",
      "4  j.k. rowling wishes snape happy birthday in th...      0\n",
      "5                        advancing the world's women      0\n",
      "6     the fascinating case for eating lab-grown meat      0\n",
      "7  this ceo will send your kids to school, if you...      0\n",
      "8  top snake handler leaves sinking huckabee camp...      1\n",
      "9  friday's morning email: inside trump's presser...      0\n"
     ]
    }
   ],
   "source": [
    "# Separate the json into sentences and labels\n",
    "sentences = []\n",
    "labels = []\n",
    "for item in srcsm_json.json():\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "print(pd.DataFrame({'sentence' : sentences[0:10], 'label':labels[0:10]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMCgxeRnRd20"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into Train and Test\n",
    "training_size =  20000\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "# Setting tokenizer properties\n",
    "vocab_size = 1000\n",
    "oov_tok = \"<OOV>\"\n",
    "# Fit the tokenizer on Training data\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "# Setting the padding properties\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "# Creating padded sequences from train and test data\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1609041055488,
     "user": {
      "displayName": "Ly Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64",
      "userId": "01585632328413993117"
     },
     "user_tz": -420
    },
    "id": "EPCbn7xxRmQm",
    "outputId": "3b209610-9448-4049-d963-6effd3c2946f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 16,433\n",
      "Trainable params: 16,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setting the model parameters\n",
    "embedding_dim = 16\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50883,
     "status": "ok",
     "timestamp": 1609041107882,
     "user": {
      "displayName": "Ly Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj1nBUdqgyGPrTg8lXGC8cHEEjZ06cg4eNIe54J=s64",
      "userId": "01585632328413993117"
     },
     "user_tz": -420
    },
    "id": "KJk_rHMDRoXc",
    "outputId": "42750d0a-7360-4ffe-8101-c20166f4f153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 - 4s - loss: 0.6809 - accuracy: 0.5602 - val_loss: 0.6581 - val_accuracy: 0.5633\n",
      "Epoch 2/30\n",
      "625/625 - 2s - loss: 0.5534 - accuracy: 0.7268 - val_loss: 0.4727 - val_accuracy: 0.7879\n",
      "Epoch 3/30\n",
      "625/625 - 2s - loss: 0.4274 - accuracy: 0.8065 - val_loss: 0.4273 - val_accuracy: 0.8009\n",
      "Epoch 4/30\n",
      "625/625 - 2s - loss: 0.3934 - accuracy: 0.8217 - val_loss: 0.4112 - val_accuracy: 0.8095\n",
      "Epoch 5/30\n",
      "625/625 - 2s - loss: 0.3813 - accuracy: 0.8275 - val_loss: 0.4045 - val_accuracy: 0.8159\n",
      "Epoch 6/30\n",
      "625/625 - 2s - loss: 0.3724 - accuracy: 0.8316 - val_loss: 0.4018 - val_accuracy: 0.8153\n",
      "Epoch 7/30\n",
      "625/625 - 2s - loss: 0.3653 - accuracy: 0.8349 - val_loss: 0.4006 - val_accuracy: 0.8147\n",
      "Epoch 8/30\n",
      "625/625 - 2s - loss: 0.3615 - accuracy: 0.8347 - val_loss: 0.4023 - val_accuracy: 0.8149\n",
      "Epoch 9/30\n",
      "625/625 - 2s - loss: 0.3586 - accuracy: 0.8346 - val_loss: 0.4016 - val_accuracy: 0.8114\n",
      "Epoch 10/30\n",
      "625/625 - 2s - loss: 0.3559 - accuracy: 0.8388 - val_loss: 0.4023 - val_accuracy: 0.8170\n",
      "Epoch 11/30\n",
      "625/625 - 2s - loss: 0.3540 - accuracy: 0.8382 - val_loss: 0.4025 - val_accuracy: 0.8165\n",
      "Epoch 12/30\n",
      "625/625 - 2s - loss: 0.3534 - accuracy: 0.8403 - val_loss: 0.4029 - val_accuracy: 0.8144\n",
      "Epoch 13/30\n",
      "625/625 - 2s - loss: 0.3522 - accuracy: 0.8410 - val_loss: 0.4048 - val_accuracy: 0.8155\n",
      "Epoch 14/30\n",
      "625/625 - 2s - loss: 0.3502 - accuracy: 0.8418 - val_loss: 0.4041 - val_accuracy: 0.8141\n",
      "Epoch 15/30\n",
      "625/625 - 2s - loss: 0.3492 - accuracy: 0.8416 - val_loss: 0.4051 - val_accuracy: 0.8113\n",
      "Epoch 16/30\n",
      "625/625 - 2s - loss: 0.3487 - accuracy: 0.8423 - val_loss: 0.4054 - val_accuracy: 0.8131\n",
      "Epoch 17/30\n",
      "625/625 - 2s - loss: 0.3478 - accuracy: 0.8417 - val_loss: 0.4066 - val_accuracy: 0.8134\n",
      "Epoch 18/30\n",
      "625/625 - 2s - loss: 0.3490 - accuracy: 0.8419 - val_loss: 0.4207 - val_accuracy: 0.8031\n",
      "Epoch 19/30\n",
      "625/625 - 2s - loss: 0.3480 - accuracy: 0.8421 - val_loss: 0.4190 - val_accuracy: 0.8043\n",
      "Epoch 20/30\n",
      "625/625 - 2s - loss: 0.3471 - accuracy: 0.8429 - val_loss: 0.4120 - val_accuracy: 0.8104\n",
      "Epoch 21/30\n",
      "625/625 - 2s - loss: 0.3481 - accuracy: 0.8401 - val_loss: 0.4070 - val_accuracy: 0.8132\n",
      "Epoch 22/30\n",
      "625/625 - 2s - loss: 0.3468 - accuracy: 0.8407 - val_loss: 0.4100 - val_accuracy: 0.8128\n",
      "Epoch 23/30\n",
      "625/625 - 2s - loss: 0.3466 - accuracy: 0.8414 - val_loss: 0.4102 - val_accuracy: 0.8103\n",
      "Epoch 24/30\n",
      "625/625 - 2s - loss: 0.3466 - accuracy: 0.8431 - val_loss: 0.4077 - val_accuracy: 0.8110\n",
      "Epoch 25/30\n",
      "625/625 - 2s - loss: 0.3464 - accuracy: 0.8431 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "625/625 - 2s - loss: 0.3459 - accuracy: 0.8436 - val_loss: 0.4124 - val_accuracy: 0.8126\n",
      "Epoch 27/30\n",
      "625/625 - 2s - loss: 0.3462 - accuracy: 0.8419 - val_loss: 0.4093 - val_accuracy: 0.8125\n",
      "Epoch 28/30\n",
      "625/625 - 2s - loss: 0.3460 - accuracy: 0.8417 - val_loss: 0.4086 - val_accuracy: 0.8117\n",
      "Epoch 29/30\n",
      "625/625 - 2s - loss: 0.3466 - accuracy: 0.8419 - val_loss: 0.4167 - val_accuracy: 0.8073\n",
      "Epoch 30/30\n",
      "625/625 - 2s - loss: 0.3458 - accuracy: 0.8426 - val_loss: 0.4153 - val_accuracy: 0.8109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting the lists to numpy arrays for Tensorflow 2.x\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)\n",
    "# Training the model\n",
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMy2blrWUkXP"
   },
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPfeVDqerem6eyFjDVBNFbX",
   "name": "4_DetectingSarcasm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
